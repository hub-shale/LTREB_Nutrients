---
title: "Judith River Watershed PCPAR02 2021 Data Processing"
output: html_document
---


```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = FALSE);
knitr::opts_chunk$set(results = "hide");

pcmetaEnv <- new.env();
```

<!--
### THIS DATA PRODUCT IS A WORK IN PROGRESS. The instrument serial number, metadata, and deployment location are assumed to be the same as stated in a previous version of the data product, but this is not yet confirmed.

This is the work flow for downloading the data for a Campbell Datalogger using a LiCor PAR transducer. The general sequence is to:

1.  Download the data from the instrument
2.  Generate initial visualization of the data and perform QAQC the data in the field technician role
3.  Finalize the primary data product.

Code in this R markdown work flow depends on the "disco" package.
-->

Generated from R markdown file **./02_protocol/`r knitr::current_input()`**, last compiled on `r Sys.time()`

```{r}

# Create target directories if none exist.

tempPath <- "./03_incremental/temp";
dir.create(
  path = tempPath,
  recursive = TRUE,
  showWarnings = FALSE
)

productPath <- "./04_product";
dir.create(
  path = productPath,
  recursive = TRUE,
  showWarnings = FALSE
);
```


```{r}
# Read the project attributes table
# and restructure for convenience.

atts <- as.data.frame(
  t(as.matrix(
    readxl::read_excel(
      path = "./01_input/meta/attributes_jrw.xlsx",
      range = readxl::cell_limits(ul = c(2, 3)),
      col_names = TRUE,
      col_types = rep("text", times = 10)
    )
  ))
);

names(atts) <- readxl::read_excel(
  path = "./01_input/meta/attributes_jrw.xlsx",
  range = readxl::cell_limits(ul = c(3, 2), lr = c(NA, 2)),
  col_names = "rownames",
  col_types = "text"
)$rownames;
atts[is.na(atts)] <- "";

```


``` {r}

# campbellSerialNumber <- "CR310";
# licorSerialNumber <- "UWQ9224";


# Add attributes to environment as metadata

pcmetaEnv$tablePAR.meta <- data.frame(
  timeStringSensor = atts$timeStringSensor,
  voltageDiffCampbell = atts$voltageDiffCampbell,
  parLicorCampbell = atts$parLicorCampbell,
  parQAQC = atts$parQAQC,
  row.names = rownames(atts)
)
```



```{r}
# Create table name

pcmetaEnv$tablePAR.name <- "PCPAR02_data_20210604-20210804"
```


```{r}
# Create table description

pcmetaEnv$tablePAR.desc <- ""
```

```{r}
# Add site ccordinates

pcmetaEnv$location <- data.frame(
  geographicDescription = "Site PCPAR02, ",
  northBoundingCoordinate = "47.05546",
  southBoundingCoordinate = "47.05546",
  eastBoundingCoordinate = "109.83412",
  westBoundingCoordinate = "109.83412"
)
```


``` {r}
# function to create plot of PAR (organized weekly)

plotPar <- function(
   df, time = NULL, file, qaqc = F
){
   if (!is.null(time)) {
     df$time <- time
   }
   attributes(df$time)$tzone <- "America/Denver"
   df$period <- cut(df$time, "7 day", labels = F)
   periods <- unique(df$period)
   
   pdf(file = file, 
       width = 8, height = 3*length(periods))
   par(mfrow = c(length(periods), 1),
       mar =c(3, 4.5, 1, 2))
   
   for (i in 1:length(periods)){
      temp <- df[df$period == periods[i],]
      
      plot(
         x = temp$time, 
         y = temp$par_avg, 
         ylab = bquote(Par ~ Flux ~ Average ~ .("(") * mu * mol ~ Photons ~ m^-2 * s^-1 * .(")")), 
         type = "l", 
         xaxt = "n", 
         xlab = " "
      )
      axis.POSIXct(
         side = 1,
         x = temp$time,
         at = seq(from = as.POSIXct("2020-06-03 00:00", tz = "America/Denver"), 
                  to = as.POSIXct("2020-09-13 00:00", tz = "America/Denver"), 
                  by = "1 day"),
         format = "%e %b",
         padj = 0.5
      );
      axis.POSIXct(
         side = 1,
         x = temp$time,
         at = seq(from = as.POSIXct("2021-03-03 00:00", tz = "America/Denver"), 
                  to = as.POSIXct("2021-03-13 00:00", tz = "America/Denver"), 
                  by = "1 day"),
         format = "%e %b",
         padj = 0.5
      );
      axis.POSIXct(
         side = 1,
         x = temp$time,
         at = seq(from = as.POSIXct("2021-03-14 00:00", tz = "America/Denver"), 
                  to = as.POSIXct("2021-11-14 00:00", tz = "America/Denver"), 
                  by = "1 day"),
         format = "%e %b",
         padj = 0.5
      );
      
   }
   if(qaqc){
      legend(
         x = "topleft", 
         legend = "nkp", 
         lty = 1, 
         bty = "n"
      )
   }
   
   dev.off()
   
}

```




## Visualize the data and perform field level QAQC

Begin processing data product. The initial data visualization is in `03_incremental/initial_visualization.pdf`.

```{r}
# Create column names
col.names <- c(
  "timeStringSensor",
  "voltageDiffCampbell",
  "parLicorCampbell"
)

# 6/04-8/17
df <- data.table::fread(
   file = "./01_input/CR800Series35439_Table1.csv",
   sep = ",",
   header = FALSE,
   skip = 4,
   drop = c(2,4), 
   col.names = names(pcmetaEnv$tablePAR.meta[,1:3]),
   stringsAsFactors = FALSE
)


# create time for plotting and sorting, and reformat in df

time <- as.POSIXct(df$timeStringSensor, format = "%Y-%m-%d %H:%M:%S", tz = "UTC")
df$timeStringSensor <- format(time, format = "%Y%m%dT%H%M%SZ")

# Plot data for initial QAQC 
plotPar(df = df, time = time, file = "03_incremental/initial_visualization.pdf")


```
<!--
When the sensor was retrieved from the site on 8/17/21, the PAR sensor was facing towards the ground and cows had clearly been near the sensor. Data taken after 8/4/21 were assumed to not be aligned with metadata and were removed.

No problems found with the remaining data. Though for this deployment, the PAR sensor was not carefully leveled to be sure the sensing surface was absolutely horizontal. Field QAQC code added and set to "unlev" for all remaining data. 
-->

Final data visualization with QAQC tags are in `04_product/final_visualization.pdf`.

```{r}
# filter out data from after 8/4
filter <- time < as.POSIXct("2021-08-04 00:00", tz = "America/Denver")
df <- df[filter,]
time <- time[filter]

plotPar(df = df, time = time, file = "04_product/final_visualization.pdf", qaqc = T)

# add QAQC code to indicate unleveled instrument
df$parFieldQAQC <- "unlev"
```


```{r}
# Add start and end times to metadata environment

pcmetaEnv$startTime <- min(time)
pcmetaEnv$endTime <- max(time)
```


## Create the site-level data product

Write the data as a CSV table, including the metadata. Write the final visualization and compile this markdown into an HTML file report.

The following files are available in the `04_product` directory:

*  PCPAR02_data_20210604-20210804.csv - The full output from the sensor.
*  final_visualization.pdf - Summary of the data in the product.
*  processing_notes.html - The compiled Rmarkdown document.


```{r}
# write data to site-level product directory
write.csv(
   x = df,
   file = "./04_product/PCPAR02_data_20210604-20210804.csv",
   row.names = FALSE
)

# write data to top level of data product
write.csv(
   x = df,
   file = "../../04_product/PCPAR02_data_20210604-20210804.csv",
   row.names = FALSE
)

```


## Write metdata object

```{r}

# write the metadata environment to temp/ as RDS

file <- sprintf(
  "%s/pc_metadata.RData",
  tempPath
);
saveRDS(
  object = pcmetaEnv,
  file = file
)

```

